\documentclass[10pt]{article}
\usepackage{NotesTeXV3}

\title{Note:\\Introduction into Deep Learning (IN2346)\\\vspace{0.5em}\large{\textit{The Art of Teaching Sands to Think}}}
\author{Yudhistira Arief Wibowo}

\begin{document}

\maketitle

\newpage

\section{Introduction}

\section{Machine Learning}

\subsection{Regressions}

\subsection{Maximum Likelihood}

\section{Deep Learning Basic}

\subsection{Layer}

\subsection{Activation Function}

\subsection{Loss Function}

\section{Optimization}

\subsection{Backpropagation}

\subsection{Gradient Decent}

\subsubsection{Stochastic Gradient Decent}

\subsection{Momentum}

\subsection{Root Mean Square Propagation (RMSProp)}

\subsection{Adaptive Moment Estimation (ADAM)}

\subsection{Newton Method}

\section{Training Neural Network}

\subsection{Data Processing}
% Splitting etc.

\subsection{Hyperparameter}

\subsection{Common Challenge}
% Underfitting etc.

\subsection{Weight Initialization}

\subsection{Regularization}

\subsubsection{Dropout}

\subsection{Batch Normalization}

\section{Convolutional Neural Network}

\subsection{Filter}

\subsection{Pooling}

\section{Popular CNN Architectures}

\subsection{LeNet}

\subsection{AlexNet}

\subsection{VGGNet}

\subsection{ResNet}
% Introduce skip connection here

\subsection{GoogleNet}
% Introduce Inception Layer here

\subsection{XceptionNet}

\subsection{U-Net}

\section{Sequential Data Deep Learning Architectures}

\subsection{Recurrent Neural Network (RNN)}

\subsection{Long Short Term Memory (LSTM)}

\subsection{Attention}

\subsection{Transformer}

\section{Generative Deep Learning Architectures}

\subsection{Variational Auto-Encoder}

\subsection{Generative Adversarial Network (GAN)}

\section{Reinforcement Learning}

\section{Closing Remarks}

\end{document}